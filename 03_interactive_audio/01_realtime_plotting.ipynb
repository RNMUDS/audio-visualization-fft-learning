{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. リアルタイム音響可視化\n",
    "\n",
    "リアルタイムで音声を処理し、動的に可視化する技術を学びます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy import signal\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. シミュレートされたリアルタイム可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeVisualizer:\n",
    "    def __init__(self, sample_rate=8000, buffer_size=1024):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.buffer_size = buffer_size\n",
    "        self.time_buffer = np.zeros(buffer_size)\n",
    "        self.freq_buffer = np.zeros(buffer_size // 2 + 1)\n",
    "        \n",
    "        # 周波数軸\n",
    "        self.frequencies = fftfreq(buffer_size, 1/sample_rate)[:buffer_size//2+1]\n",
    "        \n",
    "        # 時間軸（相対時間）\n",
    "        self.time_axis = np.arange(buffer_size) / sample_rate\n",
    "        \n",
    "        # 可視化用データの履歴\n",
    "        self.history_length = 100\n",
    "        self.spectrum_history = np.zeros((self.history_length, len(self.frequencies)))\n",
    "        self.time_index = 0\n",
    "        \n",
    "    def update_buffer(self, new_data):\n",
    "        \"\"\"新しいデータでバッファを更新\"\"\"\n",
    "        if len(new_data) != self.buffer_size:\n",
    "            raise ValueError(f\"Data size must be {self.buffer_size}\")\n",
    "        \n",
    "        self.time_buffer = new_data\n",
    "        \n",
    "        # FFT計算\n",
    "        windowed_data = new_data * np.hanning(self.buffer_size)\n",
    "        fft_result = fft(windowed_data)\n",
    "        self.freq_buffer = np.abs(fft_result[:self.buffer_size//2+1])\n",
    "        \n",
    "        # スペクトルの履歴を更新\n",
    "        self.spectrum_history[self.time_index % self.history_length] = self.freq_buffer\n",
    "        self.time_index += 1\n",
    "        \n",
    "    def get_current_spectrum(self):\n",
    "        \"\"\"現在のスペクトルを取得\"\"\"\n",
    "        return self.frequencies, self.freq_buffer\n",
    "        \n",
    "    def get_current_waveform(self):\n",
    "        \"\"\"現在の波形を取得\"\"\"\n",
    "        return self.time_axis, self.time_buffer\n",
    "        \n",
    "    def get_spectrogram_data(self):\n",
    "        \"\"\"スペクトログラム用データを取得\"\"\"\n",
    "        # 履歴の有効な部分を取得\n",
    "        valid_history = min(self.time_index, self.history_length)\n",
    "        if valid_history == 0:\n",
    "            return np.array([]), np.array([]), np.array([])\n",
    "        \n",
    "        # 時間軸（過去から現在へ）\n",
    "        time_steps = np.arange(valid_history) * (self.buffer_size / self.sample_rate)\n",
    "        \n",
    "        # スペクトルデータ（dB変換）\n",
    "        spectrum_db = 20 * np.log10(self.spectrum_history[:valid_history].T + 1e-10)\n",
    "        \n",
    "        return time_steps, self.frequencies, spectrum_db\n",
    "\n",
    "# テスト用信号生成器\n",
    "class SignalGenerator:\n",
    "    def __init__(self, sample_rate=8000):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.time = 0\n",
    "        \n",
    "    def generate_sweep(self, duration, f_start=100, f_end=1000):\n",
    "        \"\"\"周波数スイープ信号\"\"\"\n",
    "        t = np.linspace(self.time, self.time + duration, \n",
    "                       int(self.sample_rate * duration), False)\n",
    "        self.time += duration\n",
    "        return signal.chirp(t, f_start, duration, f_end, method='linear')\n",
    "        \n",
    "    def generate_multi_tone(self, duration, frequencies, amplitudes=None):\n",
    "        \"\"\"マルチトーン信号\"\"\"\n",
    "        if amplitudes is None:\n",
    "            amplitudes = [1.0] * len(frequencies)\n",
    "            \n",
    "        t = np.linspace(self.time, self.time + duration,\n",
    "                       int(self.sample_rate * duration), False)\n",
    "        \n",
    "        signal_sum = np.zeros_like(t)\n",
    "        for freq, amp in zip(frequencies, amplitudes):\n",
    "            signal_sum += amp * np.sin(2 * np.pi * freq * t)\n",
    "            \n",
    "        self.time += duration\n",
    "        return signal_sum\n",
    "        \n",
    "    def generate_noise(self, duration, noise_type='white'):\n",
    "        \"\"\"ノイズ信号\"\"\"\n",
    "        samples = int(self.sample_rate * duration)\n",
    "        \n",
    "        if noise_type == 'white':\n",
    "            noise = np.random.normal(0, 1, samples)\n",
    "        elif noise_type == 'pink':\n",
    "            # 簡易ピンクノイズ（1/f特性の近似）\n",
    "            white = np.random.normal(0, 1, samples)\n",
    "            freqs = fftfreq(samples, 1/self.sample_rate)\n",
    "            fft_white = fft(white)\n",
    "            # 周波数に反比例する重み\n",
    "            weights = 1 / np.sqrt(np.abs(freqs) + 1)\n",
    "            fft_pink = fft_white * weights\n",
    "            noise = np.real(np.fft.ifft(fft_pink))\n",
    "        \n",
    "        self.time += duration\n",
    "        return noise\n",
    "\n",
    "# リアルタイム可視化のシミュレーション\n",
    "sample_rate = 8000\n",
    "buffer_size = 512\n",
    "buffer_duration = buffer_size / sample_rate  # 約0.064秒\n",
    "\n",
    "visualizer = RealTimeVisualizer(sample_rate, buffer_size)\n",
    "generator = SignalGenerator(sample_rate)\n",
    "\n",
    "# シミュレーション用の信号シーケンス\n",
    "signal_sequence = [\n",
    "    ('スイープ', lambda: generator.generate_sweep(2.0, 200, 800)),\n",
    "    ('マルチトーン', lambda: generator.generate_multi_tone(2.0, [300, 500, 700], [1.0, 0.7, 0.5])),\n",
    "    ('ホワイトノイズ', lambda: generator.generate_noise(1.5, 'white')),\n",
    "    ('ピンクノイズ', lambda: generator.generate_noise(1.5, 'pink')),\n",
    "]\n",
    "\n",
    "# 各信号タイプのスナップショットを可視化\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "for signal_idx, (signal_name, signal_func) in enumerate(signal_sequence):\n",
    "    # 信号を生成\n",
    "    test_signal = signal_func()\n",
    "    \n",
    "    # バッファサイズに分割して処理\n",
    "    num_buffers = len(test_signal) // buffer_size\n",
    "    \n",
    "    # 中間地点のバッファを表示用に選択\n",
    "    mid_buffer_idx = num_buffers // 2\n",
    "    start_sample = mid_buffer_idx * buffer_size\n",
    "    end_sample = start_sample + buffer_size\n",
    "    \n",
    "    buffer_data = test_signal[start_sample:end_sample]\n",
    "    visualizer.update_buffer(buffer_data)\n",
    "    \n",
    "    # 現在の波形\n",
    "    plt.subplot(4, 3, signal_idx * 3 + 1)\n",
    "    time_axis, waveform = visualizer.get_current_waveform()\n",
    "    plt.plot(time_axis * 1000, waveform, 'b-', linewidth=2)  # ms単位\n",
    "    plt.title(f'{signal_name}（波形）')\n",
    "    plt.xlabel('時間 (ms)')\n",
    "    plt.ylabel('振幅')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 現在のスペクトル\n",
    "    plt.subplot(4, 3, signal_idx * 3 + 2)\n",
    "    frequencies, spectrum = visualizer.get_current_spectrum()\n",
    "    plt.plot(frequencies, 20 * np.log10(spectrum + 1e-10), 'r-', linewidth=2)\n",
    "    plt.title(f'{signal_name}（スペクトル）')\n",
    "    plt.xlabel('周波数 (Hz)')\n",
    "    plt.ylabel('振幅 (dB)')\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, 1500)\n",
    "    \n",
    "    # 複数バッファを処理してスペクトログラムを作成\n",
    "    plt.subplot(4, 3, signal_idx * 3 + 3)\n",
    "    \n",
    "    # 全信号を段階的に処理\n",
    "    visualizer_temp = RealTimeVisualizer(sample_rate, buffer_size)\n",
    "    for i in range(0, len(test_signal) - buffer_size, buffer_size):\n",
    "        buffer_chunk = test_signal[i:i + buffer_size]\n",
    "        visualizer_temp.update_buffer(buffer_chunk)\n",
    "    \n",
    "    # スペクトログラムデータを取得\n",
    "    time_steps, freq_axis, spectrogram_data = visualizer_temp.get_spectrogram_data()\n",
    "    \n",
    "    if len(time_steps) > 0:\n",
    "        plt.pcolormesh(time_steps, freq_axis, spectrogram_data, \n",
    "                      shading='gouraud', cmap='viridis')\n",
    "        plt.title(f'{signal_name}（スペクトログラム）')\n",
    "        plt.xlabel('時間 (秒)')\n",
    "        plt.ylabel('周波数 (Hz)')\n",
    "        plt.ylim(0, 1500)\n",
    "        plt.colorbar(label='振幅 (dB)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"リアルタイム可視化の特徴:\")\n",
    "print(f\"- バッファサイズ: {buffer_size} サンプル\")\n",
    "print(f\"- 更新間隔: {buffer_duration*1000:.1f} ms\")\n",
    "print(f\"- 周波数分解能: {sample_rate/buffer_size:.1f} Hz\")\n",
    "print(f\"- 時間分解能: {buffer_duration*1000:.1f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. インタラクティブなパラメータ調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インタラクティブなパラメータ調整のシミュレーション\n",
    "class InteractiveAudioProcessor:\n",
    "    def __init__(self, sample_rate=8000):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.parameters = {\n",
    "            'frequency': 440.0,\n",
    "            'amplitude': 1.0,\n",
    "            'filter_cutoff': 1000.0,\n",
    "            'noise_level': 0.0,\n",
    "            'harmonic_strength': 0.5\n",
    "        }\n",
    "        \n",
    "    def update_parameter(self, param_name, value):\n",
    "        \"\"\"パラメータを更新\"\"\"\n",
    "        if param_name in self.parameters:\n",
    "            self.parameters[param_name] = value\n",
    "            \n",
    "    def generate_signal(self, duration=1.0):\n",
    "        \"\"\"現在のパラメータで信号を生成\"\"\"\n",
    "        t = np.linspace(0, duration, int(self.sample_rate * duration), False)\n",
    "        \n",
    "        # 基本波形（基音 + 倍音）\n",
    "        freq = self.parameters['frequency']\n",
    "        amp = self.parameters['amplitude']\n",
    "        harmonic_str = self.parameters['harmonic_strength']\n",
    "        \n",
    "        signal = (amp * np.sin(2 * np.pi * freq * t) +\n",
    "                 harmonic_str * amp * 0.5 * np.sin(2 * np.pi * freq * 2 * t) +\n",
    "                 harmonic_str * amp * 0.3 * np.sin(2 * np.pi * freq * 3 * t))\n",
    "        \n",
    "        # ノイズを追加\n",
    "        noise_level = self.parameters['noise_level']\n",
    "        if noise_level > 0:\n",
    "            noise = noise_level * np.random.normal(0, 1, len(signal))\n",
    "            signal += noise\n",
    "            \n",
    "        return t, signal\n",
    "        \n",
    "    def apply_filter(self, signal):\n",
    "        \"\"\"ローパスフィルタを適用\"\"\"\n",
    "        cutoff = self.parameters['filter_cutoff']\n",
    "        nyquist = self.sample_rate / 2\n",
    "        \n",
    "        if cutoff >= nyquist:\n",
    "            return signal  # フィルタなし\n",
    "            \n",
    "        # バターワースフィルタ\n",
    "        normalized_cutoff = cutoff / nyquist\n",
    "        b, a = signal.butter(4, normalized_cutoff, btype='low')\n",
    "        filtered_signal = signal.filtfilt(b, a, signal)\n",
    "        \n",
    "        return filtered_signal\n",
    "\n",
    "# パラメータセットの比較\n",
    "processor = InteractiveAudioProcessor()\n",
    "\n",
    "parameter_sets = [\n",
    "    {'name': 'デフォルト', 'frequency': 440, 'amplitude': 1.0, 'filter_cutoff': 2000, 'noise_level': 0.0, 'harmonic_strength': 0.5},\n",
    "    {'name': '低音', 'frequency': 220, 'amplitude': 1.0, 'filter_cutoff': 2000, 'noise_level': 0.0, 'harmonic_strength': 0.5},\n",
    "    {'name': '高音', 'frequency': 880, 'amplitude': 1.0, 'filter_cutoff': 2000, 'noise_level': 0.0, 'harmonic_strength': 0.5},\n",
    "    {'name': '倍音豊富', 'frequency': 440, 'amplitude': 1.0, 'filter_cutoff': 2000, 'noise_level': 0.0, 'harmonic_strength': 1.0},\n",
    "    {'name': 'ローパス', 'frequency': 440, 'amplitude': 1.0, 'filter_cutoff': 800, 'noise_level': 0.0, 'harmonic_strength': 0.5},\n",
    "    {'name': 'ノイズあり', 'frequency': 440, 'amplitude': 1.0, 'filter_cutoff': 2000, 'noise_level': 0.3, 'harmonic_strength': 0.5}\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "for i, param_set in enumerate(parameter_sets):\n",
    "    # パラメータを設定\n",
    "    for param_name, value in param_set.items():\n",
    "        if param_name != 'name':\n",
    "            processor.update_parameter(param_name, value)\n",
    "    \n",
    "    # 信号を生成\n",
    "    t, original_signal = processor.generate_signal(0.5)  # 0.5秒\n",
    "    filtered_signal = processor.apply_filter(original_signal)\n",
    "    \n",
    "    # FFT解析\n",
    "    fft_original = fft(original_signal)\n",
    "    fft_filtered = fft(filtered_signal)\n",
    "    frequencies = fftfreq(len(original_signal), 1/processor.sample_rate)\n",
    "    positive_mask = frequencies >= 0\n",
    "    \n",
    "    # 時間波形（元信号 vs フィルタ後）\n",
    "    plt.subplot(6, 3, i * 3 + 1)\n",
    "    plt.plot(t[:400], original_signal[:400], 'b-', alpha=0.7, label='元信号', linewidth=2)\n",
    "    plt.plot(t[:400], filtered_signal[:400], 'r-', label='フィルタ後', linewidth=2)\n",
    "    plt.title(f'{param_set[\"name\"]}（波形）')\n",
    "    plt.ylabel('振幅')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # スペクトル比較\n",
    "    plt.subplot(6, 3, i * 3 + 2)\n",
    "    plt.plot(frequencies[positive_mask], 20 * np.log10(np.abs(fft_original)[positive_mask] + 1e-10), \n",
    "            'b-', alpha=0.7, label='元スペクトル', linewidth=2)\n",
    "    plt.plot(frequencies[positive_mask], 20 * np.log10(np.abs(fft_filtered)[positive_mask] + 1e-10), \n",
    "            'r-', label='フィルタ後', linewidth=2)\n",
    "    \n",
    "    # フィルタのカットオフ周波数を表示\n",
    "    cutoff = processor.parameters['filter_cutoff']\n",
    "    plt.axvline(x=cutoff, color='orange', linestyle='--', alpha=0.7, label=f'カットオフ: {cutoff} Hz')\n",
    "    \n",
    "    plt.title(f'{param_set[\"name\"]}（スペクトル）')\n",
    "    plt.ylabel('振幅 (dB)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, 2000)\n",
    "    \n",
    "    # パラメータ表示\n",
    "    plt.subplot(6, 3, i * 3 + 3)\n",
    "    param_text = f\"\"\"周波数: {processor.parameters['frequency']:.0f} Hz\n",
    "振幅: {processor.parameters['amplitude']:.1f}\n",
    "フィルタ: {processor.parameters['filter_cutoff']:.0f} Hz\n",
    "ノイズ: {processor.parameters['noise_level']:.1f}\n",
    "倍音: {processor.parameters['harmonic_strength']:.1f}\"\"\"\n",
    "    \n",
    "    plt.text(0.1, 0.5, param_text, transform=plt.gca().transAxes, \n",
    "            fontsize=12, verticalalignment='center',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.8))\n",
    "    plt.title(f'{param_set[\"name\"]}（パラメータ）')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    if i == len(parameter_sets) - 1:\n",
    "        plt.subplot(6, 3, i * 3 + 1)\n",
    "        plt.xlabel('時間 (秒)')\n",
    "        plt.subplot(6, 3, i * 3 + 2)\n",
    "        plt.xlabel('周波数 (Hz)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"インタラクティブ処理のメリット:\")\n",
    "print(\"1. リアルタイムでの効果確認\")\n",
    "print(\"2. パラメータの即座の調整\")\n",
    "print(\"3. 直感的な音響効果の理解\")\n",
    "print(\"4. 教育・学習への応用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 動的スペクトログラム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動的スペクトログラムのシミュレーション\n",
    "class DynamicSpectrogram:\n",
    "    def __init__(self, sample_rate=8000, window_size=512, max_time_frames=200):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.window_size = window_size\n",
    "        self.max_time_frames = max_time_frames\n",
    "        \n",
    "        # スペクトログラムデータ（周波数 x 時間）\n",
    "        self.spectrogram_data = np.zeros((window_size // 2 + 1, max_time_frames))\n",
    "        self.current_frame = 0\n",
    "        \n",
    "        # 周波数軸\n",
    "        self.frequencies = fftfreq(window_size, 1/sample_rate)[:window_size//2+1]\n",
    "        \n",
    "        # 時間軸（相対時間）\n",
    "        self.time_per_frame = window_size / sample_rate\n",
    "        \n",
    "    def add_frame(self, audio_frame):\n",
    "        \"\"\"新しい音声フレームを追加\"\"\"\n",
    "        if len(audio_frame) != self.window_size:\n",
    "            raise ValueError(f\"Frame size must be {self.window_size}\")\n",
    "        \n",
    "        # FFT計算\n",
    "        windowed_frame = audio_frame * np.hanning(self.window_size)\n",
    "        fft_result = fft(windowed_frame)\n",
    "        magnitude = np.abs(fft_result[:self.window_size//2+1])\n",
    "        \n",
    "        # スペクトログラムを左にシフト（古いデータを削除）\n",
    "        self.spectrogram_data[:, :-1] = self.spectrogram_data[:, 1:]\n",
    "        \n",
    "        # 新しいフレームを右端に追加\n",
    "        self.spectrogram_data[:, -1] = magnitude\n",
    "        \n",
    "        self.current_frame += 1\n",
    "        \n",
    "    def get_spectrogram(self):\n",
    "        \"\"\"現在のスペクトログラムを取得\"\"\"\n",
    "        # 有効なフレーム数\n",
    "        valid_frames = min(self.current_frame, self.max_time_frames)\n",
    "        \n",
    "        # 時間軸（現在時刻を基準とした相対時間）\n",
    "        time_axis = np.arange(-valid_frames + 1, 1) * self.time_per_frame\n",
    "        \n",
    "        # dB変換\n",
    "        spectrogram_db = 20 * np.log10(self.spectrogram_data[:, -valid_frames:] + 1e-10)\n",
    "        \n",
    "        return time_axis, self.frequencies, spectrogram_db\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"スペクトログラムをリセット\"\"\"\n",
    "        self.spectrogram_data.fill(0)\n",
    "        self.current_frame = 0\n",
    "\n",
    "# 時間変化する複雑な信号の生成\n",
    "def create_dynamic_signal(duration=10.0, sample_rate=8000):\n",
    "    \"\"\"時間とともに変化する複雑な信号\"\"\"\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    signal = np.zeros_like(t)\n",
    "    \n",
    "    # セクション1: 上昇スイープ (0-2秒)\n",
    "    mask1 = (t >= 0) & (t < 2)\n",
    "    signal[mask1] = signal.chirp(t[mask1], 200, 2, 800, method='linear')\n",
    "    \n",
    "    # セクション2: 複数トーン (2-4秒)\n",
    "    mask2 = (t >= 2) & (t < 4)\n",
    "    for freq in [300, 500, 700]:\n",
    "        signal[mask2] += np.sin(2 * np.pi * freq * t[mask2]) / 3\n",
    "    \n",
    "    # セクション3: 下降スイープ (4-6秒)\n",
    "    mask3 = (t >= 4) & (t < 6)\n",
    "    signal[mask3] = signal.chirp(t[mask3] - 4, 800, 2, 200, method='linear')\n",
    "    \n",
    "    # セクション4: AM変調信号 (6-8秒)\n",
    "    mask4 = (t >= 6) & (t < 8)\n",
    "    carrier_freq = 600\n",
    "    mod_freq = 5  # 5Hz変調\n",
    "    carrier = np.sin(2 * np.pi * carrier_freq * t[mask4])\n",
    "    modulation = 0.5 * (1 + np.sin(2 * np.pi * mod_freq * t[mask4]))\n",
    "    signal[mask4] = carrier * modulation\n",
    "    \n",
    "    # セクション5: ノイズバースト (8-10秒)\n",
    "    mask5 = (t >= 8) & (t < 10)\n",
    "    np.random.seed(42)\n",
    "    noise = np.random.normal(0, 0.5, np.sum(mask5))\n",
    "    # 時間的にゲートされたノイズ\n",
    "    gate = np.sin(np.pi * (t[mask5] - 8) / 2)**2  # 0から1に変化\n",
    "    signal[mask5] = noise * gate\n",
    "    \n",
    "    return t, signal\n",
    "\n",
    "# 動的スペクトログラムのデモ\n",
    "sample_rate = 8000\n",
    "window_size = 256\n",
    "hop_size = window_size // 4  # 75%オーバーラップ\n",
    "\n",
    "# 信号生成\n",
    "t, dynamic_signal = create_dynamic_signal(8.0, sample_rate)\n",
    "\n",
    "# スペクトログラム生成\n",
    "spectrogram = DynamicSpectrogram(sample_rate, window_size, max_time_frames=150)\n",
    "\n",
    "# フレームごとに処理\n",
    "snapshots = []  # 特定時刻でのスナップショット\n",
    "snapshot_times = [1.0, 3.0, 5.0, 7.0]  # スナップショットを取る時刻\n",
    "\n",
    "for i in range(0, len(dynamic_signal) - window_size, hop_size):\n",
    "    frame = dynamic_signal[i:i + window_size]\n",
    "    spectrogram.add_frame(frame)\n",
    "    \n",
    "    # 現在時刻\n",
    "    current_time = i / sample_rate\n",
    "    \n",
    "    # スナップショット時刻の場合、データを保存\n",
    "    for snapshot_time in snapshot_times:\n",
    "        if abs(current_time - snapshot_time) < hop_size / sample_rate:\n",
    "            time_axis, freq_axis, spec_data = spectrogram.get_spectrogram()\n",
    "            snapshots.append({\n",
    "                'time': snapshot_time,\n",
    "                'time_axis': time_axis.copy(),\n",
    "                'freq_axis': freq_axis.copy(),\n",
    "                'data': spec_data.copy()\n",
    "            })\n",
    "\n",
    "# 最終スペクトログラム\n",
    "final_time_axis, final_freq_axis, final_spec_data = spectrogram.get_spectrogram()\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# 元の信号\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.plot(t, dynamic_signal, 'b-', linewidth=1)\n",
    "plt.title('動的信号（全体）')\n",
    "plt.xlabel('時間 (秒)')\n",
    "plt.ylabel('振幅')\n",
    "plt.grid(True)\n",
    "\n",
    "# スナップショット時刻をマーク\n",
    "for snap_time in snapshot_times:\n",
    "    plt.axvline(x=snap_time, color='r', linestyle='--', alpha=0.7)\n",
    "\n",
    "# 最終スペクトログラム\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.pcolormesh(final_time_axis, final_freq_axis, final_spec_data,\n",
    "              shading='gouraud', cmap='viridis')\n",
    "plt.title('動的スペクトログラム（最終状態）')\n",
    "plt.xlabel('相対時間 (秒)')\n",
    "plt.ylabel('周波数 (Hz)')\n",
    "plt.colorbar(label='振幅 (dB)')\n",
    "plt.ylim(0, 1500)\n",
    "\n",
    "# 各スナップショットでのスペクトログラム\n",
    "for i, snapshot in enumerate(snapshots[:4]):\n",
    "    plt.subplot(3, 3, i + 4)\n",
    "    plt.pcolormesh(snapshot['time_axis'], snapshot['freq_axis'], snapshot['data'],\n",
    "                  shading='gouraud', cmap='plasma')\n",
    "    plt.title(f'スナップショット t={snapshot[\"time\"]:.1f}s')\n",
    "    plt.xlabel('相対時間 (秒)')\n",
    "    plt.ylabel('周波数 (Hz)')\n",
    "    plt.ylim(0, 1500)\n",
    "    \n",
    "    if i < 2:\n",
    "        plt.colorbar(label='振幅 (dB)')\n",
    "\n",
    "# 特定周波数での時間変化\n",
    "plt.subplot(3, 3, 8)\n",
    "# 500Hz付近の強度変化\n",
    "freq_idx = np.argmin(np.abs(final_freq_axis - 500))\n",
    "intensity_500hz = final_spec_data[freq_idx, :]\n",
    "plt.plot(final_time_axis, intensity_500hz, 'g-', linewidth=2, label='500Hz')\n",
    "\n",
    "# 700Hz付近の強度変化\n",
    "freq_idx = np.argmin(np.abs(final_freq_axis - 700))\n",
    "intensity_700hz = final_spec_data[freq_idx, :]\n",
    "plt.plot(final_time_axis, intensity_700hz, 'r-', linewidth=2, label='700Hz')\n",
    "\n",
    "plt.title('特定周波数の時間変化')\n",
    "plt.xlabel('相対時間 (秒)')\n",
    "plt.ylabel('振幅 (dB)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 平均スペクトル\n",
    "plt.subplot(3, 3, 9)\n",
    "mean_spectrum = np.mean(final_spec_data, axis=1)\n",
    "plt.plot(final_freq_axis, mean_spectrum, 'purple', linewidth=2)\n",
    "plt.title('平均スペクトル')\n",
    "plt.xlabel('周波数 (Hz)')\n",
    "plt.ylabel('平均振幅 (dB)')\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 1500)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"動的スペクトログラムの応用:\")\n",
    "print(\"1. リアルタイム音響監視\")\n",
    "print(\"2. 音楽の可視化\")\n",
    "print(\"3. 音響異常検出\")\n",
    "print(\"4. 音声認識の前処理\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習問題\n",
    "\n",
    "1. マイクからのリアルタイム音声入力を使ったスペクトラムアナライザーを作成してみましょう\n",
    "2. 音楽に合わせて色や形が変化するビジュアライザーを実装してみましょう\n",
    "3. 声の特徴（ピッチ、フォルマント）をリアルタイムで追跡するシステムを作ってみましょう"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}