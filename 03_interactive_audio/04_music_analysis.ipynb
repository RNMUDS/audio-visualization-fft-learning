{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. 音楽分析\n",
    "\n",
    "音楽の構造や特徴を自動分析する技術を学びます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftfreq\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ビート検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeatDetector:\n",
    "    def __init__(self, sample_rate=44100):\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "    def onset_detection(self, audio, hop_length=512):\n",
    "        \"\"\"オンセット検出による簡易ビート検出\"\"\"\n",
    "        # スペクトログラム計算\n",
    "        f, t, Sxx = signal.spectrogram(audio, self.sample_rate, \n",
    "                                      nperseg=1024, noverlap=512)\n",
    "        \n",
    "        # スペクトル変化量を計算\n",
    "        spectral_diff = np.diff(Sxx, axis=1)\n",
    "        \n",
    "        # 正の変化のみ（増加）\n",
    "        spectral_diff[spectral_diff < 0] = 0\n",
    "        \n",
    "        # 各時刻での総変化量\n",
    "        onset_strength = np.sum(spectral_diff, axis=0)\n",
    "        \n",
    "        # ピーク検出\n",
    "        peaks, _ = signal.find_peaks(onset_strength, \n",
    "                                   height=np.mean(onset_strength) + np.std(onset_strength),\n",
    "                                   distance=int(0.1 * len(onset_strength) / (t[-1] - t[0])))\n",
    "        \n",
    "        # 時刻に変換\n",
    "        beat_times = t[1:][peaks]  # t[1:]は差分のため\n",
    "        \n",
    "        return beat_times, onset_strength, t[1:]\n",
    "        \n",
    "    def tempo_estimation(self, beat_times):\n",
    "        \"\"\"テンポ推定\"\"\"\n",
    "        if len(beat_times) < 2:\n",
    "            return 0\n",
    "            \n",
    "        # ビート間隔\n",
    "        intervals = np.diff(beat_times)\n",
    "        \n",
    "        # 中央値を使用（外れ値に頑健）\n",
    "        median_interval = np.median(intervals)\n",
    "        \n",
    "        # BPM計算\n",
    "        bpm = 60.0 / median_interval\n",
    "        \n",
    "        return bpm\n",
    "\n",
    "# テスト用音楽信号の生成\n",
    "def create_drum_pattern(sample_rate, duration, bpm=120):\n",
    "    \"\"\"ドラムパターンの生成\"\"\"\n",
    "    beat_interval = 60.0 / bpm\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    signal = np.zeros_like(t)\n",
    "    \n",
    "    # キックドラム（低周波）\n",
    "    for beat_time in np.arange(0, duration, beat_interval):\n",
    "        beat_idx = int(beat_time * sample_rate)\n",
    "        if beat_idx < len(signal):\n",
    "            # 短い低周波パルス\n",
    "            pulse_duration = 0.1\n",
    "            pulse_samples = int(pulse_duration * sample_rate)\n",
    "            t_pulse = np.linspace(0, pulse_duration, pulse_samples)\n",
    "            \n",
    "            # 60Hzのサイン波にエンベロープ\n",
    "            kick = np.sin(2 * np.pi * 60 * t_pulse) * np.exp(-t_pulse * 20)\n",
    "            \n",
    "            end_idx = min(beat_idx + pulse_samples, len(signal))\n",
    "            signal[beat_idx:end_idx] += kick[:end_idx-beat_idx]\n",
    "    \n",
    "    # ハイハット（高周波、オフビート）\n",
    "    for beat_time in np.arange(beat_interval/2, duration, beat_interval):\n",
    "        beat_idx = int(beat_time * sample_rate)\n",
    "        if beat_idx < len(signal):\n",
    "            # 短い高周波ノイズ\n",
    "            pulse_duration = 0.05\n",
    "            pulse_samples = int(pulse_duration * sample_rate)\n",
    "            \n",
    "            np.random.seed(int(beat_time * 1000))\n",
    "            hihat = np.random.normal(0, 0.3, pulse_samples) * np.exp(-np.arange(pulse_samples) * 0.001)\n",
    "            \n",
    "            end_idx = min(beat_idx + pulse_samples, len(signal))\n",
    "            signal[beat_idx:end_idx] += hihat[:end_idx-beat_idx]\n",
    "    \n",
    "    return t, signal\n",
    "\n",
    "# ビート検出のテスト\n",
    "sample_rate = 22050  # 軽量化\n",
    "duration = 8.0\n",
    "test_bpm = 128\n",
    "\n",
    "detector = BeatDetector(sample_rate)\n",
    "\n",
    "# テスト信号生成\n",
    "t_drum, drum_signal = create_drum_pattern(sample_rate, duration, test_bpm)\n",
    "\n",
    "# ビート検出実行\n",
    "beat_times, onset_strength, onset_times = detector.onset_detection(drum_signal)\n",
    "estimated_bpm = detector.tempo_estimation(beat_times)\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# 元の信号\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.plot(t_drum, drum_signal, 'b-', linewidth=1)\n",
    "plt.title(f'ドラムパターン（{test_bpm} BPM）')\n",
    "plt.ylabel('振幅')\n",
    "plt.grid(True)\n",
    "\n",
    "# 理論的なビート位置をマーク\n",
    "theoretical_beats = np.arange(0, duration, 60.0/test_bpm)\n",
    "for beat in theoretical_beats:\n",
    "    plt.axvline(x=beat, color='g', linestyle='--', alpha=0.5)\n",
    "\n",
    "# オンセット強度\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.plot(onset_times, onset_strength, 'r-', linewidth=2)\n",
    "plt.scatter(beat_times, onset_strength[np.isin(onset_times, beat_times, assume_unique=True)], \n",
    "           color='red', s=50, zorder=5)\n",
    "plt.title('オンセット強度と検出されたビート')\n",
    "plt.ylabel('強度')\n",
    "plt.grid(True)\n",
    "\n",
    "# スペクトログラム\n",
    "plt.subplot(3, 2, 3)\n",
    "f, t_spec, Sxx = signal.spectrogram(drum_signal, sample_rate, nperseg=512, noverlap=256)\n",
    "plt.pcolormesh(t_spec, f, 10 * np.log10(Sxx + 1e-10), shading='gouraud', cmap='viridis')\n",
    "\n",
    "# 検出されたビートをマーク\n",
    "for beat in beat_times:\n",
    "    plt.axvline(x=beat, color='red', linestyle='-', alpha=0.8, linewidth=2)\n",
    "\n",
    "plt.title('スペクトログラムと検出ビート')\n",
    "plt.ylabel('周波数 (Hz)')\n",
    "plt.ylim(0, 1000)\n",
    "plt.colorbar(label='振幅 (dB)')\n",
    "\n",
    "# ビート間隔の分析\n",
    "plt.subplot(3, 2, 4)\n",
    "if len(beat_times) > 1:\n",
    "    intervals = np.diff(beat_times)\n",
    "    plt.plot(beat_times[1:], intervals, 'mo-', linewidth=2, markersize=8)\n",
    "    plt.axhline(y=60.0/test_bpm, color='g', linestyle='--', \n",
    "               label=f'理論値: {60.0/test_bpm:.3f}s')\n",
    "    plt.axhline(y=np.median(intervals), color='r', linestyle='-', \n",
    "               label=f'検出値: {np.median(intervals):.3f}s')\n",
    "    plt.title('ビート間隔の変化')\n",
    "    plt.xlabel('時間 (秒)')\n",
    "    plt.ylabel('間隔 (秒)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "# 結果サマリー\n",
    "plt.subplot(3, 2, (5, 6))\n",
    "plt.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "ビート検出結果\n",
    "\n",
    "理論BPM: {test_bpm}\n",
    "検出BPM: {estimated_bpm:.1f}\n",
    "誤差: {abs(estimated_bpm - test_bpm):.1f} BPM\n",
    "\n",
    "検出されたビート数: {len(beat_times)}\n",
    "理論ビート数: {len(theoretical_beats)}\n",
    "\n",
    "平均ビート間隔: {np.mean(np.diff(beat_times)):.3f}s\n",
    "理論ビート間隔: {60.0/test_bpm:.3f}s\n",
    "\"\"\"\n",
    "\n",
    "plt.text(0.1, 0.5, summary_text, fontsize=14, verticalalignment='center',\n",
    "        bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"ビート検出の原理:\")\n",
    "print(\"1. スペクトログラムの時間変化を分析\")\n",
    "print(\"2. 急激な音響変化（オンセット）を検出\")\n",
    "print(\"3. ピーク検出でビートタイミングを特定\")\n",
    "print(\"4. ビート間隔からテンポを推定\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 音楽的特徴量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicFeatures:\n",
    "    def __init__(self, sample_rate=44100):\n",
    "        self.sample_rate = sample_rate\n",
    "        \n",
    "    def spectral_centroid(self, audio, window_size=2048):\n",
    "        \"\"\"スペクトル重心（明るさの指標）\"\"\"\n",
    "        hop_length = window_size // 4\n",
    "        centroids = []\n",
    "        \n",
    "        for i in range(0, len(audio) - window_size, hop_length):\n",
    "            frame = audio[i:i + window_size]\n",
    "            windowed_frame = frame * np.hanning(window_size)\n",
    "            \n",
    "            spectrum = np.abs(fft(windowed_frame))\n",
    "            freqs = fftfreq(window_size, 1/self.sample_rate)\n",
    "            \n",
    "            # 正の周波数のみ\n",
    "            positive_freqs = freqs[:window_size//2]\n",
    "            positive_spectrum = spectrum[:window_size//2]\n",
    "            \n",
    "            # 重心計算\n",
    "            if np.sum(positive_spectrum) > 0:\n",
    "                centroid = np.sum(positive_freqs * positive_spectrum) / np.sum(positive_spectrum)\n",
    "                centroids.append(centroid)\n",
    "            else:\n",
    "                centroids.append(0)\n",
    "                \n",
    "        return np.array(centroids)\n",
    "        \n",
    "    def spectral_bandwidth(self, audio, window_size=2048):\n",
    "        \"\"\"スペクトル帯域幅\"\"\"\n",
    "        hop_length = window_size // 4\n",
    "        bandwidths = []\n",
    "        centroids = self.spectral_centroid(audio, window_size)\n",
    "        \n",
    "        for i, centroid in enumerate(centroids):\n",
    "            frame_start = i * hop_length\n",
    "            frame = audio[frame_start:frame_start + window_size]\n",
    "            \n",
    "            if len(frame) == window_size:\n",
    "                windowed_frame = frame * np.hanning(window_size)\n",
    "                spectrum = np.abs(fft(windowed_frame))\n",
    "                freqs = fftfreq(window_size, 1/self.sample_rate)\n",
    "                \n",
    "                positive_freqs = freqs[:window_size//2]\n",
    "                positive_spectrum = spectrum[:window_size//2]\n",
    "                \n",
    "                if np.sum(positive_spectrum) > 0:\n",
    "                    bandwidth = np.sqrt(np.sum(((positive_freqs - centroid) ** 2) * positive_spectrum) / \n",
    "                                      np.sum(positive_spectrum))\n",
    "                    bandwidths.append(bandwidth)\n",
    "                else:\n",
    "                    bandwidths.append(0)\n",
    "            else:\n",
    "                bandwidths.append(0)\n",
    "                \n",
    "        return np.array(bandwidths)\n",
    "        \n",
    "    def zero_crossing_rate(self, audio, window_size=2048):\n",
    "        \"\"\"ゼロクロッシングレート\"\"\"\n",
    "        hop_length = window_size // 4\n",
    "        zcr = []\n",
    "        \n",
    "        for i in range(0, len(audio) - window_size, hop_length):\n",
    "            frame = audio[i:i + window_size]\n",
    "            \n",
    "            # 符号変化の検出\n",
    "            signs = np.sign(frame)\n",
    "            sign_changes = np.diff(signs)\n",
    "            zero_crossings = np.sum(sign_changes != 0)\n",
    "            \n",
    "            zcr.append(zero_crossings / window_size)\n",
    "            \n",
    "        return np.array(zcr)\n",
    "        \n",
    "    def rms_energy(self, audio, window_size=2048):\n",
    "        \"\"\"RMSエネルギー\"\"\"\n",
    "        hop_length = window_size // 4\n",
    "        rms = []\n",
    "        \n",
    "        for i in range(0, len(audio) - window_size, hop_length):\n",
    "            frame = audio[i:i + window_size]\n",
    "            rms_value = np.sqrt(np.mean(frame ** 2))\n",
    "            rms.append(rms_value)\n",
    "            \n",
    "        return np.array(rms)\n",
    "        \n",
    "    def spectral_rolloff(self, audio, window_size=2048, percentile=85):\n",
    "        \"\"\"スペクトルロールオフ\"\"\"\n",
    "        hop_length = window_size // 4\n",
    "        rolloffs = []\n",
    "        \n",
    "        for i in range(0, len(audio) - window_size, hop_length):\n",
    "            frame = audio[i:i + window_size]\n",
    "            windowed_frame = frame * np.hanning(window_size)\n",
    "            \n",
    "            spectrum = np.abs(fft(windowed_frame))\n",
    "            freqs = fftfreq(window_size, 1/self.sample_rate)\n",
    "            \n",
    "            positive_freqs = freqs[:window_size//2]\n",
    "            positive_spectrum = spectrum[:window_size//2]\n",
    "            \n",
    "            # 累積エネルギー\n",
    "            cumulative_energy = np.cumsum(positive_spectrum)\n",
    "            total_energy = cumulative_energy[-1]\n",
    "            \n",
    "            if total_energy > 0:\n",
    "                threshold = (percentile / 100.0) * total_energy\n",
    "                rolloff_idx = np.where(cumulative_energy >= threshold)[0]\n",
    "                \n",
    "                if len(rolloff_idx) > 0:\n",
    "                    rolloffs.append(positive_freqs[rolloff_idx[0]])\n",
    "                else:\n",
    "                    rolloffs.append(positive_freqs[-1])\n",
    "            else:\n",
    "                rolloffs.append(0)\n",
    "                \n",
    "        return np.array(rolloffs)\n",
    "\n",
    "# 異なる音楽スタイルの特徴量比較\n",
    "def create_music_styles(sample_rate, duration=4.0):\n",
    "    \"\"\"異なる音楽スタイルの信号を生成\"\"\"\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    \n",
    "    styles = {}\n",
    "    \n",
    "    # 1. クラシック風（サイン波ベース、豊富なハーモニー）\n",
    "    classical = np.zeros_like(t)\n",
    "    for harmonic in range(1, 6):\n",
    "        freq = 220 * harmonic\n",
    "        amplitude = 1.0 / harmonic\n",
    "        classical += amplitude * np.sin(2 * np.pi * freq * t)\n",
    "    classical *= np.exp(-t * 0.5)  # 減衰\n",
    "    styles['クラシック'] = classical\n",
    "    \n",
    "    # 2. エレクトロニック（方形波、鋭いエンベロープ）\n",
    "    electronic = signal.square(2 * np.pi * 440 * t) * 0.5\n",
    "    # ADSRエンベロープ\n",
    "    adsr = np.ones_like(t)\n",
    "    attack_samples = int(0.05 * sample_rate)\n",
    "    release_start = int(3.5 * sample_rate)\n",
    "    adsr[:attack_samples] = np.linspace(0, 1, attack_samples)\n",
    "    adsr[release_start:] = np.linspace(1, 0, len(adsr) - release_start)\n",
    "    electronic *= adsr\n",
    "    styles['エレクトロニック'] = electronic\n",
    "    \n",
    "    # 3. ロック風（歪み、高エネルギー）\n",
    "    rock_base = np.sin(2 * np.pi * 220 * t) + 0.5 * np.sin(2 * np.pi * 440 * t)\n",
    "    # 歪み効果\n",
    "    rock = np.tanh(rock_base * 3) * 0.7\n",
    "    styles['ロック'] = rock\n",
    "    \n",
    "    # 4. アンビエント（ノイズベース、ローパス）\n",
    "    np.random.seed(42)\n",
    "    ambient_noise = np.random.normal(0, 0.3, len(t))\n",
    "    # ローパスフィルタ\n",
    "    nyquist = sample_rate / 2\n",
    "    cutoff = 500 / nyquist\n",
    "    b, a = signal.butter(4, cutoff, btype='low')\n",
    "    ambient = signal.filtfilt(b, a, ambient_noise)\n",
    "    styles['アンビエント'] = ambient\n",
    "    \n",
    "    return t, styles\n",
    "\n",
    "# 特徴量分析\n",
    "features = MusicFeatures(sample_rate)\n",
    "t_music, music_styles = create_music_styles(sample_rate)\n",
    "\n",
    "# 各スタイルの特徴量を計算\n",
    "style_features = {}\n",
    "for style_name, audio in music_styles.items():\n",
    "    style_features[style_name] = {\n",
    "        'centroid': features.spectral_centroid(audio),\n",
    "        'bandwidth': features.spectral_bandwidth(audio),\n",
    "        'zcr': features.zero_crossing_rate(audio),\n",
    "        'rms': features.rms_energy(audio),\n",
    "        'rolloff': features.spectral_rolloff(audio)\n",
    "    }\n",
    "\n",
    "# 可視化\n",
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "# 各スタイルの波形\n",
    "for i, (style_name, audio) in enumerate(music_styles.items()):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.plot(t_music[:4000], audio[:4000], linewidth=1)\n",
    "    plt.title(f'{style_name}（波形）')\n",
    "    plt.ylabel('振幅')\n",
    "    plt.grid(True)\n",
    "\n",
    "# 特徴量の時間変化\n",
    "feature_names = ['centroid', 'bandwidth', 'zcr', 'rms']\n",
    "feature_labels = ['スペクトル重心 (Hz)', '帯域幅 (Hz)', 'ゼロクロッシング率', 'RMSエネルギー']\n",
    "\n",
    "for i, (feat_name, feat_label) in enumerate(zip(feature_names, feature_labels)):\n",
    "    plt.subplot(4, 4, i + 5)\n",
    "    \n",
    "    for style_name in music_styles.keys():\n",
    "        feat_values = style_features[style_name][feat_name]\n",
    "        time_axis = np.linspace(0, len(t_music)/sample_rate, len(feat_values))\n",
    "        plt.plot(time_axis, feat_values, label=style_name, linewidth=2)\n",
    "    \n",
    "    plt.title(feat_label)\n",
    "    plt.ylabel(feat_label)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "# 特徴量の平均値比較\n",
    "plt.subplot(4, 4, 9)\n",
    "styles = list(music_styles.keys())\n",
    "centroid_means = [np.mean(style_features[style]['centroid']) for style in styles]\n",
    "colors = ['blue', 'red', 'green', 'purple']\n",
    "\n",
    "bars = plt.bar(styles, centroid_means, color=colors, alpha=0.7)\n",
    "plt.title('平均スペクトル重心')\n",
    "plt.ylabel('周波数 (Hz)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "for bar, value in zip(bars, centroid_means):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(centroid_means)*0.01,\n",
    "            f'{value:.0f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# ZCR vs RMS散布図\n",
    "plt.subplot(4, 4, 10)\n",
    "for i, style in enumerate(styles):\n",
    "    zcr_mean = np.mean(style_features[style]['zcr'])\n",
    "    rms_mean = np.mean(style_features[style]['rms'])\n",
    "    plt.scatter(zcr_mean, rms_mean, color=colors[i], s=100, label=style, alpha=0.8)\n",
    "    plt.text(zcr_mean, rms_mean, style, fontsize=9, ha='left', va='bottom')\n",
    "\n",
    "plt.xlabel('平均ゼロクロッシング率')\n",
    "plt.ylabel('平均RMSエネルギー')\n",
    "plt.title('ZCR vs RMS')\n",
    "plt.grid(True)\n",
    "\n",
    "# 特徴量レーダーチャート用データ準備\n",
    "plt.subplot(4, 4, 11)\n",
    "feature_matrix = np.zeros((len(styles), len(feature_names)))\n",
    "\n",
    "for i, style in enumerate(styles):\n",
    "    for j, feat_name in enumerate(feature_names):\n",
    "        feature_matrix[i, j] = np.mean(style_features[style][feat_name])\n",
    "\n",
    "# 正規化（0-1スケール）\n",
    "feature_matrix_norm = (feature_matrix - feature_matrix.min(axis=0)) / \\\n",
    "                     (feature_matrix.max(axis=0) - feature_matrix.min(axis=0))\n",
    "\n",
    "# ヒートマップ\n",
    "im = plt.imshow(feature_matrix_norm, cmap='viridis', aspect='auto')\n",
    "plt.xticks(range(len(feature_names)), [name.replace('_', '\\n') for name in feature_names])\n",
    "plt.yticks(range(len(styles)), styles)\n",
    "plt.title('特徴量ヒートマップ\\n（正規化済み）')\n",
    "plt.colorbar(im, label='正規化値')\n",
    "\n",
    "# 特徴量統計\n",
    "plt.subplot(4, 4, 12)\n",
    "plt.axis('off')\n",
    "\n",
    "stats_text = \"特徴量の特性:\\n\\n\"\n",
    "for style in styles:\n",
    "    centroid_mean = np.mean(style_features[style]['centroid'])\n",
    "    zcr_mean = np.mean(style_features[style]['zcr'])\n",
    "    stats_text += f\"{style}:\\n\"\n",
    "    stats_text += f\"  重心: {centroid_mean:.0f} Hz\\n\"\n",
    "    stats_text += f\"  ZCR: {zcr_mean:.3f}\\n\\n\"\n",
    "\n",
    "plt.text(0.05, 0.95, stats_text, fontsize=10, verticalalignment='top',\n",
    "        bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightgray\", alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"音楽的特徴量の意味:\")\n",
    "print(\"- スペクトル重心: 音の明るさ（高いほど明るい）\")\n",
    "print(\"- スペクトル帯域幅: 音色の豊かさ\")\n",
    "print(\"- ゼロクロッシング率: ノイズ性の指標\")\n",
    "print(\"- RMSエネルギー: 音の大きさ\")\n",
    "print(\"- スペクトルロールオフ: 高周波成分の存在\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習問題\n",
    "\n",
    "1. 実際の音楽ファイルを読み込んで特徴量分析を行ってみましょう\n",
    "2. 機械学習を使って音楽ジャンル分類システムを構築してみましょう\n",
    "3. コード進行の自動検出システムを実装してみましょう"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}