{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. 短時間フーリエ変換（STFT）\n",
    "\n",
    "時間と周波数の両方を同時に分析するSTFTについて学びます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.fft import fft, fftfreq\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. STFTの基本概念"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_stft(x, window_size, overlap, window_type='hann', sample_rate=44100):\n",
    "    \"\"\"\n",
    "    手動でSTFTを実装（理解のため）\n",
    "    \"\"\"\n",
    "    hop_size = window_size - overlap\n",
    "    \n",
    "    # 窓関数の作成\n",
    "    if window_type == 'hann':\n",
    "        window = np.hanning(window_size)\n",
    "    elif window_type == 'hamming':\n",
    "        window = np.hamming(window_size)\n",
    "    elif window_type == 'rectangular':\n",
    "        window = np.ones(window_size)\n",
    "    \n",
    "    # 時間軸とフレーム数の計算\n",
    "    num_frames = (len(x) - window_size) // hop_size + 1\n",
    "    \n",
    "    # STFT結果を格納する配列\n",
    "    stft_result = np.zeros((window_size // 2 + 1, num_frames), dtype=complex)\n",
    "    \n",
    "    # 各フレームでFFT\n",
    "    for frame in range(num_frames):\n",
    "        start = frame * hop_size\n",
    "        end = start + window_size\n",
    "        \n",
    "        # 窓関数を適用\n",
    "        windowed_signal = x[start:end] * window\n",
    "        \n",
    "        # FFT\n",
    "        fft_result = fft(windowed_signal)\n",
    "        \n",
    "        # 正の周波数のみ保存\n",
    "        stft_result[:, frame] = fft_result[:window_size // 2 + 1]\n",
    "    \n",
    "    # 時間軸と周波数軸\n",
    "    times = np.arange(num_frames) * hop_size / sample_rate\n",
    "    frequencies = np.fft.fftfreq(window_size, 1/sample_rate)[:window_size // 2 + 1]\n",
    "    \n",
    "    return frequencies, times, stft_result\n",
    "\n",
    "# 時間とともに周波数が変化する信号（チャープ）\n",
    "sample_rate = 8000\n",
    "duration = 3.0\n",
    "t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "\n",
    "# チャープ信号（100Hz → 1000Hz）\n",
    "chirp_signal = signal.chirp(t, 100, duration, 1000, method='linear')\n",
    "\n",
    "# 複数音が混在する信号\n",
    "multi_tone = (np.sin(2 * np.pi * 200 * t) * (t < 1) +\n",
    "             np.sin(2 * np.pi * 500 * t) * ((t >= 1) & (t < 2)) +\n",
    "             np.sin(2 * np.pi * 800 * t) * (t >= 2))\n",
    "\n",
    "# 窓サイズの影響を比較\n",
    "window_sizes = [128, 256, 512, 1024]\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# チャープ信号のSTFT比較\n",
    "for i, win_size in enumerate(window_sizes):\n",
    "    # 手動STFT\n",
    "    freqs, times, stft_result = manual_stft(chirp_signal, win_size, win_size//2, 'hann', sample_rate)\n",
    "    \n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    magnitude = np.abs(stft_result)\n",
    "    plt.pcolormesh(times, freqs, 20 * np.log10(magnitude + 1e-10), \n",
    "                  shading='gouraud', cmap='viridis')\n",
    "    plt.title(f'チャープ信号\\n窓サイズ: {win_size}')\n",
    "    plt.ylabel('周波数 (Hz)')\n",
    "    plt.ylim(0, 1500)\n",
    "    \n",
    "    # 時間分解能と周波数分解能を表示\n",
    "    time_res = (win_size // 2) / sample_rate * 1000  # ms\n",
    "    freq_res = sample_rate / win_size  # Hz\n",
    "    plt.text(0.1, 1300, f'時間分解能: {time_res:.1f} ms\\n周波数分解能: {freq_res:.1f} Hz', \n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),\n",
    "            fontsize=9)\n",
    "\n",
    "# マルチトーン信号のSTFT比較\n",
    "for i, win_size in enumerate(window_sizes):\n",
    "    freqs, times, stft_result = manual_stft(multi_tone, win_size, win_size//2, 'hann', sample_rate)\n",
    "    \n",
    "    plt.subplot(2, 4, i + 5)\n",
    "    magnitude = np.abs(stft_result)\n",
    "    plt.pcolormesh(times, times, 20 * np.log10(magnitude + 1e-10), \n",
    "                  shading='gouraud', cmap='plasma')\n",
    "    plt.title(f'マルチトーン信号\\n窓サイズ: {win_size}')\n",
    "    plt.xlabel('時間 (秒)')\n",
    "    plt.ylabel('周波数 (Hz)')\n",
    "    plt.ylim(0, 1000)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 元の信号も表示\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(t, chirp_signal)\n",
    "plt.title('チャープ信号（100Hz → 1000Hz）')\n",
    "plt.ylabel('振幅')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(t, multi_tone)\n",
    "plt.title('マルチトーン信号（200Hz → 500Hz → 800Hz）')\n",
    "plt.xlabel('時間 (秒)')\n",
    "plt.ylabel('振幅')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"窓サイズの影響:\")\n",
    "print(\"- 小さい窓: 高い時間分解能、低い周波数分解能\")\n",
    "print(\"- 大きい窓: 低い時間分解能、高い周波数分解能\")\n",
    "print(\"- トレードオフの関係（不確定性原理）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 音楽信号のSTFT解析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音楽的な信号の生成\n",
    "def create_musical_sequence(sample_rate, duration_per_note=0.5):\n",
    "    \"\"\"\n",
    "    音楽的なシーケンスを生成\n",
    "    \"\"\"\n",
    "    # C Major Scale (ド レ ミ ファ ソ ラ シ ド)\n",
    "    notes = [261.63, 293.66, 329.63, 349.23, 392.00, 440.00, 493.88, 523.25]  # Hz\n",
    "    \n",
    "    total_duration = len(notes) * duration_per_note\n",
    "    t_total = np.linspace(0, total_duration, int(sample_rate * total_duration), False)\n",
    "    \n",
    "    music_signal = np.zeros_like(t_total)\n",
    "    \n",
    "    for i, note_freq in enumerate(notes):\n",
    "        start_time = i * duration_per_note\n",
    "        end_time = (i + 1) * duration_per_note\n",
    "        \n",
    "        start_idx = int(start_time * sample_rate)\n",
    "        end_idx = int(end_time * sample_rate)\n",
    "        \n",
    "        # ノートの時間軸\n",
    "        note_t = t_total[start_idx:end_idx] - start_time\n",
    "        \n",
    "        # 楽器的な音（倍音を含む）\n",
    "        note_signal = (np.sin(2 * np.pi * note_freq * note_t) +\n",
    "                      0.5 * np.sin(2 * np.pi * note_freq * 2 * note_t) +\n",
    "                      0.3 * np.sin(2 * np.pi * note_freq * 3 * note_t))\n",
    "        \n",
    "        # ADSR エンベロープ\n",
    "        envelope = np.ones_like(note_t)\n",
    "        attack_samples = int(0.05 * sample_rate)  # 50ms attack\n",
    "        release_samples = int(0.1 * sample_rate)  # 100ms release\n",
    "        \n",
    "        if len(envelope) > attack_samples:\n",
    "            envelope[:attack_samples] = np.linspace(0, 1, attack_samples)\n",
    "        if len(envelope) > release_samples:\n",
    "            envelope[-release_samples:] = np.linspace(1, 0, release_samples)\n",
    "        \n",
    "        music_signal[start_idx:end_idx] = note_signal * envelope\n",
    "    \n",
    "    return t_total, music_signal, notes\n",
    "\n",
    "# 和音の生成\n",
    "def create_chord_progression(sample_rate):\n",
    "    \"\"\"\n",
    "    和音進行を生成\n",
    "    \"\"\"\n",
    "    # C - Am - F - G progression\n",
    "    chords = [\n",
    "        [261.63, 329.63, 392.00],  # C major (C-E-G)\n",
    "        [220.00, 261.63, 329.63],  # A minor (A-C-E)\n",
    "        [174.61, 220.00, 261.63],  # F major (F-A-C)\n",
    "        [196.00, 246.94, 293.66]   # G major (G-B-D)\n",
    "    ]\n",
    "    \n",
    "    chord_duration = 1.0  # 1秒\n",
    "    total_duration = len(chords) * chord_duration\n",
    "    t_total = np.linspace(0, total_duration, int(sample_rate * total_duration), False)\n",
    "    \n",
    "    chord_signal = np.zeros_like(t_total)\n",
    "    \n",
    "    for i, chord in enumerate(chords):\n",
    "        start_idx = int(i * chord_duration * sample_rate)\n",
    "        end_idx = int((i + 1) * chord_duration * sample_rate)\n",
    "        \n",
    "        chord_t = t_total[start_idx:end_idx] - i * chord_duration\n",
    "        \n",
    "        # 和音の各音を合成\n",
    "        chord_sound = np.zeros_like(chord_t)\n",
    "        for freq in chord:\n",
    "            chord_sound += np.sin(2 * np.pi * freq * chord_t)\n",
    "        \n",
    "        chord_signal[start_idx:end_idx] = chord_sound / len(chord)  # 正規化\n",
    "    \n",
    "    return t_total, chord_signal, chords\n",
    "\n",
    "# 音楽信号の生成\n",
    "t_music, music_signal, notes = create_musical_sequence(sample_rate, 0.4)\n",
    "t_chord, chord_signal, chords = create_chord_progression(sample_rate)\n",
    "\n",
    "# STFTパラメータ\n",
    "nperseg = 512\n",
    "noverlap = nperseg // 2\n",
    "\n",
    "# メロディーのSTFT\n",
    "f_music, t_stft_music, Zxx_music = signal.stft(music_signal, sample_rate, \n",
    "                                              nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "# 和音のSTFT\n",
    "f_chord, t_stft_chord, Zxx_chord = signal.stft(chord_signal, sample_rate,\n",
    "                                              nperseg=nperseg, noverlap=noverlap)\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# メロディー - 時間波形\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.plot(t_music, music_signal)\n",
    "plt.title('メロディー（C Major Scale）')\n",
    "plt.ylabel('振幅')\n",
    "plt.grid(True)\n",
    "\n",
    "# メロディー - スペクトログラム\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.pcolormesh(t_stft_music, f_music, 20 * np.log10(np.abs(Zxx_music) + 1e-10),\n",
    "              shading='gouraud', cmap='viridis')\n",
    "plt.title('メロディーのスペクトログラム')\n",
    "plt.ylabel('周波数 (Hz)')\n",
    "plt.colorbar(label='振幅 (dB)')\n",
    "plt.ylim(0, 1000)\n",
    "\n",
    "# 理論値（ノートの周波数）をプロット\n",
    "for i, note_freq in enumerate(notes):\n",
    "    note_time = i * 0.4 + 0.2  # 各ノートの中央時刻\n",
    "    plt.plot(note_time, note_freq, 'wo', markersize=8, markeredgecolor='red')\n",
    "    plt.text(note_time, note_freq + 50, f'{note_freq:.0f}', \n",
    "            ha='center', color='white', fontsize=8)\n",
    "\n",
    "# 和音 - 時間波形\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.plot(t_chord, chord_signal)\n",
    "plt.title('和音進行（C-Am-F-G）')\n",
    "plt.ylabel('振幅')\n",
    "plt.grid(True)\n",
    "\n",
    "# 和音 - スペクトログラム\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.pcolormesh(t_stft_chord, f_chord, 20 * np.log10(np.abs(Zxx_chord) + 1e-10),\n",
    "              shading='gouraud', cmap='plasma')\n",
    "plt.title('和音のスペクトログラム')\n",
    "plt.ylabel('周波数 (Hz)')\n",
    "plt.colorbar(label='振幅 (dB)')\n",
    "plt.ylim(0, 800)\n",
    "\n",
    "# 理論値（和音の構成音）をプロット\n",
    "for i, chord in enumerate(chords):\n",
    "    chord_time = i * 1.0 + 0.5  # 各和音の中央時刻\n",
    "    for freq in chord:\n",
    "        plt.plot(chord_time, freq, 'wo', markersize=6, markeredgecolor='red')\n",
    "\n",
    "# 周波数解析（特定時刻でのスペクトル）\n",
    "plt.subplot(3, 2, 5)\n",
    "# メロディーの3番目のノート（ミ）の時刻\n",
    "note_time_idx = np.argmin(np.abs(t_stft_music - 1.0))  # 約1秒\n",
    "spectrum_note = np.abs(Zxx_music[:, note_time_idx])\n",
    "plt.plot(f_music, 20 * np.log10(spectrum_note + 1e-10), 'b-', linewidth=2, label='ミ（329.63 Hz）')\n",
    "plt.axvline(x=329.63, color='r', linestyle='--', label='基音')\n",
    "plt.axvline(x=329.63*2, color='r', linestyle=':', alpha=0.7, label='2倍音')\n",
    "plt.axvline(x=329.63*3, color='r', linestyle=':', alpha=0.7, label='3倍音')\n",
    "plt.title('単一ノートのスペクトル（t=1.0s）')\n",
    "plt.xlabel('周波数 (Hz)')\n",
    "plt.ylabel('振幅 (dB)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 1500)\n",
    "\n",
    "# 和音解析（特定時刻でのスペクトル）\n",
    "plt.subplot(3, 2, 6)\n",
    "# 最初の和音（C major）の時刻\n",
    "chord_time_idx = np.argmin(np.abs(t_stft_chord - 0.5))  # 約0.5秒\n",
    "spectrum_chord = np.abs(Zxx_chord[:, chord_time_idx])\n",
    "plt.plot(f_chord, 20 * np.log10(spectrum_chord + 1e-10), 'g-', linewidth=2, label='C major')\n",
    "\n",
    "# C major和音の構成音をマーク\n",
    "c_major = [261.63, 329.63, 392.00]\n",
    "for freq in c_major:\n",
    "    plt.axvline(x=freq, color='r', linestyle='--', alpha=0.7)\n",
    "    plt.text(freq, max(20 * np.log10(spectrum_chord + 1e-10)) - 10, \n",
    "            f'{freq:.0f}', rotation=90, ha='center', fontsize=9)\n",
    "\n",
    "plt.title('和音のスペクトル（t=0.5s, C major）')\n",
    "plt.xlabel('周波数 (Hz)')\n",
    "plt.ylabel('振幅 (dB)')\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 800)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. STFTの逆変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT逆変換の実演\n",
    "def stft_filtering_demo():\n",
    "    \"\"\"\n",
    "    STFTを使った時間-周波数領域でのフィルタリングデモ\n",
    "    \"\"\"\n",
    "    # 複雑な信号の生成（音楽 + ノイズ）\n",
    "    duration = 4.0\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    \n",
    "    # 基本信号（メロディー）\n",
    "    melody_freqs = [261.63, 293.66, 329.63, 349.23]  # C-D-E-F\n",
    "    melody = np.zeros_like(t)\n",
    "    \n",
    "    for i, freq in enumerate(melody_freqs):\n",
    "        start_time = i\n",
    "        end_time = i + 1\n",
    "        mask = (t >= start_time) & (t < end_time)\n",
    "        melody[mask] = np.sin(2 * np.pi * freq * t[mask])\n",
    "    \n",
    "    # ノイズを追加\n",
    "    np.random.seed(42)\n",
    "    noise = 0.5 * np.random.normal(0, 1, len(t))\n",
    "    \n",
    "    # 妨害信号（高周波数）\n",
    "    interference = 0.3 * np.sin(2 * np.pi * 1500 * t) * (np.sin(2 * np.pi * 2 * t) > 0)\n",
    "    \n",
    "    # 合成信号\n",
    "    noisy_signal = melody + noise + interference\n",
    "    \n",
    "    # STFT\n",
    "    f, t_stft, Zxx_noisy = signal.stft(noisy_signal, sample_rate, \n",
    "                                      nperseg=512, noverlap=256)\n",
    "    \n",
    "    # フィルタリング（時間-周波数マスク）\n",
    "    # 1. ローパスフィルタ（1000Hz以下を保持）\n",
    "    lowpass_mask = f <= 1000\n",
    "    Zxx_lowpass = Zxx_noisy.copy()\n",
    "    Zxx_lowpass[~lowpass_mask, :] = 0\n",
    "    \n",
    "    # 2. ノイズゲート（振幅が小さい成分を除去）\n",
    "    magnitude = np.abs(Zxx_noisy)\n",
    "    threshold = np.percentile(magnitude, 70)  # 70パーセンタイル以下を除去\n",
    "    noise_gate_mask = magnitude > threshold\n",
    "    Zxx_gated = Zxx_noisy * noise_gate_mask\n",
    "    \n",
    "    # 3. 時間選択フィルタ（特定時間帯のみ保持）\n",
    "    time_mask = (t_stft >= 1.0) & (t_stft <= 3.0)  # 1-3秒\n",
    "    Zxx_time_filtered = Zxx_noisy.copy()\n",
    "    Zxx_time_filtered[:, ~time_mask] = 0\n",
    "    \n",
    "    # 逆STFT\n",
    "    _, cleaned_lowpass = signal.istft(Zxx_lowpass, sample_rate, nperseg=512, noverlap=256)\n",
    "    _, cleaned_gated = signal.istft(Zxx_gated, sample_rate, nperseg=512, noverlap=256)\n",
    "    _, cleaned_time = signal.istft(Zxx_time_filtered, sample_rate, nperseg=512, noverlap=256)\n",
    "    \n",
    "    return (t, melody, noisy_signal, cleaned_lowpass, cleaned_gated, cleaned_time,\n",
    "           f, t_stft, Zxx_noisy, Zxx_lowpass, Zxx_gated, Zxx_time_filtered)\n",
    "\n",
    "# フィルタリングデモを実行\n",
    "results = stft_filtering_demo()\n",
    "(t, melody, noisy_signal, cleaned_lowpass, cleaned_gated, cleaned_time,\n",
    " f, t_stft, Zxx_noisy, Zxx_lowpass, Zxx_gated, Zxx_time_filtered) = results\n",
    "\n",
    "plt.figure(figsize=(18, 15))\n",
    "\n",
    "# 時間領域の比較\n",
    "signals = [melody, noisy_signal, cleaned_lowpass, cleaned_gated, cleaned_time]\n",
    "signal_names = ['元のメロディー', 'ノイズ付き信号', 'ローパスフィルタ後', 'ノイズゲート後', '時間フィルタ後']\n",
    "\n",
    "for i, (sig, name) in enumerate(zip(signals, signal_names)):\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.plot(t[:len(sig)], sig, linewidth=2)\n",
    "    plt.title(name)\n",
    "    plt.ylabel('振幅')\n",
    "    plt.grid(True)\n",
    "    if i == 4:\n",
    "        plt.xlabel('時間 (秒)')\n",
    "\n",
    "# スペクトログラムの比較\n",
    "spectrograms = [Zxx_noisy, Zxx_lowpass, Zxx_gated, Zxx_time_filtered]\n",
    "spectrogram_names = ['元のスペクトログラム', 'ローパスフィルタ', 'ノイズゲート', '時間フィルタ']\n",
    "\n",
    "for i, (Zxx, name) in enumerate(zip(spectrograms, spectrogram_names)):\n",
    "    plt.subplot(4, 5, i + 6)\n",
    "    plt.pcolormesh(t_stft, f, 20 * np.log10(np.abs(Zxx) + 1e-10),\n",
    "                  shading='gouraud', cmap='viridis')\n",
    "    plt.title(name)\n",
    "    plt.ylabel('周波数 (Hz)')\n",
    "    plt.ylim(0, 2000)\n",
    "    if i == 3:\n",
    "        plt.xlabel('時間 (秒)')\n",
    "\n",
    "# フィルタマスクの可視化\n",
    "plt.subplot(4, 5, 11)\n",
    "lowpass_mask = f <= 1000\n",
    "mask_2d = np.outer(lowpass_mask.astype(float), np.ones(len(t_stft)))\n",
    "plt.pcolormesh(t_stft, f, mask_2d, shading='gouraud', cmap='RdYlBu')\n",
    "plt.title('ローパスマスク')\n",
    "plt.ylabel('周波数 (Hz)')\n",
    "plt.ylim(0, 2000)\n",
    "\n",
    "plt.subplot(4, 5, 12)\n",
    "magnitude = np.abs(Zxx_noisy)\n",
    "threshold = np.percentile(magnitude, 70)\n",
    "gate_mask = (magnitude > threshold).astype(float)\n",
    "plt.pcolormesh(t_stft, f, gate_mask, shading='gouraud', cmap='RdYlBu')\n",
    "plt.title('ノイズゲートマスク')\n",
    "plt.ylabel('周波数 (Hz)')\n",
    "plt.ylim(0, 2000)\n",
    "\n",
    "plt.subplot(4, 5, 13)\n",
    "time_mask = (t_stft >= 1.0) & (t_stft <= 3.0)\n",
    "time_mask_2d = np.outer(np.ones(len(f)), time_mask.astype(float))\n",
    "plt.pcolormesh(t_stft, f, time_mask_2d, shading='gouraud', cmap='RdYlBu')\n",
    "plt.title('時間マスク')\n",
    "plt.ylabel('周波数 (Hz)')\n",
    "plt.ylim(0, 2000)\n",
    "\n",
    "# エラー解析\n",
    "plt.subplot(4, 5, 15)\n",
    "errors = [\n",
    "    np.mean((melody - noisy_signal[:len(melody)])**2),\n",
    "    np.mean((melody - cleaned_lowpass[:len(melody)])**2),\n",
    "    np.mean((melody - cleaned_gated[:len(melody)])**2),\n",
    "    np.mean((melody - cleaned_time[:len(melody)])**2)\n",
    "]\n",
    "method_names = ['ノイズあり', 'ローパス', 'ノイズゲート', '時間フィルタ']\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "bars = plt.bar(method_names, errors, color=colors, alpha=0.7)\n",
    "plt.title('復元誤差（MSE）')\n",
    "plt.ylabel('平均二乗誤差')\n",
    "plt.xticks(rotation=45)\n",
    "plt.yscale('log')\n",
    "\n",
    "for bar, error in zip(bars, errors):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() * 1.5,\n",
    "            f'{error:.2e}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"STFT逆変換の応用:\")\n",
    "print(\"1. 時間-周波数領域での選択的フィルタリング\")\n",
    "print(\"2. ノイズ除去\")\n",
    "print(\"3. 音響効果処理\")\n",
    "print(\"4. 音楽の分離・抽出\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習問題\n",
    "\n",
    "1. 異なる窓関数（Hanning, Hamming, Blackman）がSTFTに与える影響を比較してみましょう\n",
    "2. 楽器音を録音してSTFT解析し、アタック・サスティン・リリースの特徴を観察してみましょう\n",
    "3. STFTを使って特定の周波数成分だけを抽出する音響効果を作ってみましょう"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}