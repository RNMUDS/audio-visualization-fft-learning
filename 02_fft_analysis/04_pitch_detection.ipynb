{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. ピッチ検出\n",
    "\n",
    "音の基本周波数（ピッチ）を検出する様々な手法を学びます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, fftfreq\n",
    "from scipy.signal import correlate, find_peaks\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 自己相関によるピッチ検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation_pitch_detection(signal, sample_rate, min_freq=80, max_freq=800):\n",
    "    \"\"\"\n",
    "    自己相関によるピッチ検出\n",
    "    \"\"\"\n",
    "    # 自己相関の計算\n",
    "    autocorr = correlate(signal, signal, mode='full')\n",
    "    autocorr = autocorr[len(autocorr)//2:]\n",
    "    \n",
    "    # 正規化\n",
    "    autocorr = autocorr / autocorr[0]\n",
    "    \n",
    "    # ピッチ範囲に対応するラグ範囲\n",
    "    min_lag = int(sample_rate / max_freq)\n",
    "    max_lag = int(sample_rate / min_freq)\n",
    "    \n",
    "    # 指定範囲でピークを検索\n",
    "    search_autocorr = autocorr[min_lag:max_lag]\n",
    "    peaks, _ = find_peaks(search_autocorr, height=0.3)\n",
    "    \n",
    "    if len(peaks) > 0:\n",
    "        # 最大のピークを選択\n",
    "        best_peak_idx = peaks[np.argmax(search_autocorr[peaks])]\n",
    "        lag = best_peak_idx + min_lag\n",
    "        pitch = sample_rate / lag\n",
    "        confidence = search_autocorr[best_peak_idx]\n",
    "    else:\n",
    "        pitch = 0\n",
    "        confidence = 0\n",
    "        lag = 0\n",
    "    \n",
    "    return pitch, confidence, autocorr, lag\n",
    "\n",
    "# テスト信号の生成\n",
    "sample_rate = 8000\n",
    "duration = 1.0\n",
    "t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "\n",
    "# 異なるピッチの信号をテスト\n",
    "test_pitches = [110, 220, 330, 440]  # Hz\n",
    "noise_levels = [0, 0.1, 0.3, 0.5]\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "for i, (pitch, noise_level) in enumerate(zip(test_pitches, noise_levels)):\n",
    "    # 倍音を含む信号の生成\n",
    "    signal = (np.sin(2 * np.pi * pitch * t) + \n",
    "             0.5 * np.sin(2 * np.pi * pitch * 2 * t) +\n",
    "             0.3 * np.sin(2 * np.pi * pitch * 3 * t))\n",
    "    \n",
    "    # ノイズを追加\n",
    "    if noise_level > 0:\n",
    "        np.random.seed(42 + i)\n",
    "        signal += noise_level * np.random.normal(0, 1, len(signal))\n",
    "    \n",
    "    # ピッチ検出\n",
    "    detected_pitch, confidence, autocorr, lag = autocorrelation_pitch_detection(\n",
    "        signal, sample_rate)\n",
    "    \n",
    "    # 信号の表示\n",
    "    plt.subplot(4, 3, i*3 + 1)\n",
    "    plt.plot(t[:400], signal[:400], 'b-', linewidth=2)\n",
    "    plt.title(f'信号: {pitch} Hz (ノイズ: {noise_level})')\n",
    "    plt.ylabel('振幅')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 自己相関関数\n",
    "    plt.subplot(4, 3, i*3 + 2)\n",
    "    lag_axis = np.arange(len(autocorr)) / sample_rate * 1000  # ms\n",
    "    plt.plot(lag_axis[:1000], autocorr[:1000], 'g-', linewidth=2)\n",
    "    \n",
    "    if detected_pitch > 0:\n",
    "        period_ms = 1000 / detected_pitch\n",
    "        plt.axvline(x=period_ms, color='r', linestyle='--', \n",
    "                   label=f'検出周期: {period_ms:.1f} ms')\n",
    "    \n",
    "    plt.title('自己相関関数')\n",
    "    plt.xlabel('ラグ (ms)')\n",
    "    plt.ylabel('相関係数')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # 結果まとめ\n",
    "    plt.subplot(4, 3, i*3 + 3)\n",
    "    plt.text(0.1, 0.8, f'真のピッチ: {pitch} Hz', fontsize=12, \n",
    "            transform=plt.gca().transAxes)\n",
    "    plt.text(0.1, 0.6, f'検出ピッチ: {detected_pitch:.1f} Hz', fontsize=12,\n",
    "            transform=plt.gca().transAxes, color='red')\n",
    "    plt.text(0.1, 0.4, f'誤差: {abs(detected_pitch - pitch):.1f} Hz', fontsize=12,\n",
    "            transform=plt.gca().transAxes)\n",
    "    plt.text(0.1, 0.2, f'信頼度: {confidence:.2f}', fontsize=12,\n",
    "            transform=plt.gca().transAxes)\n",
    "    \n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.title('検出結果')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"自己相関法の特徴:\")\n",
    "print(\"- 周期性のある信号に対して有効\")\n",
    "print(\"- 倍音があっても基音を検出可能\")\n",
    "print(\"- ノイズに対してある程度頑健\")\n",
    "print(\"- 計算コストが比較的低い\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. FFTベースのピッチ検出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_pitch_detection(signal, sample_rate):\n",
    "    \"\"\"\n",
    "    FFTベースのピッチ検出（倍音パターン認識）\n",
    "    \"\"\"\n",
    "    # FFT\n",
    "    fft_result = fft(signal)\n",
    "    frequencies = fftfreq(len(signal), 1/sample_rate)\n",
    "    positive_mask = frequencies >= 0\n",
    "    \n",
    "    freq_positive = frequencies[positive_mask]\n",
    "    amplitude_positive = np.abs(fft_result[positive_mask])\n",
    "    \n",
    "    # ピーク検出\n",
    "    peaks, _ = find_peaks(amplitude_positive, \n",
    "                         height=np.max(amplitude_positive) * 0.1,\n",
    "                         distance=10)\n",
    "    \n",
    "    peak_frequencies = freq_positive[peaks]\n",
    "    peak_amplitudes = amplitude_positive[peaks]\n",
    "    \n",
    "    # 基音候補を探索\n",
    "    best_fundamental = 0\n",
    "    best_score = 0\n",
    "    \n",
    "    for candidate_freq in peak_frequencies:\n",
    "        if candidate_freq < 50 or candidate_freq > 800:  # 範囲外は除外\n",
    "            continue\n",
    "        \n",
    "        # この候補が基音だと仮定して倍音のスコアを計算\n",
    "        score = 0\n",
    "        harmonic_count = 0\n",
    "        \n",
    "        for harmonic in range(1, 8):  # 7倍音まで\n",
    "            target_freq = candidate_freq * harmonic\n",
    "            if target_freq > sample_rate / 2:\n",
    "                break\n",
    "            \n",
    "            # 最も近いピークを探す\n",
    "            distances = np.abs(peak_frequencies - target_freq)\n",
    "            closest_idx = np.argmin(distances)\n",
    "            \n",
    "            # 許容誤差内にピークがあるか\n",
    "            if distances[closest_idx] < candidate_freq * 0.1:  # 10%の誤差許容\n",
    "                # 振幅で重み付けしたスコア\n",
    "                weight = peak_amplitudes[closest_idx] / np.max(peak_amplitudes)\n",
    "                score += weight / harmonic  # 高次倍音は重みを下げる\n",
    "                harmonic_count += 1\n",
    "        \n",
    "        # 倍音の数も考慮\n",
    "        score *= (harmonic_count / 7)  # 正規化\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_fundamental = candidate_freq\n",
    "    \n",
    "    return best_fundamental, best_score, freq_positive, amplitude_positive, peak_frequencies, peak_amplitudes\n",
    "\n",
    "# FFT法とHPS（Harmonic Product Spectrum）法の比較\n",
    "def harmonic_product_spectrum(signal, sample_rate, num_harmonics=5):\n",
    "    \"\"\"\n",
    "    ハーモニック積スペクトル法\n",
    "    \"\"\"\n",
    "    # FFT\n",
    "    fft_result = fft(signal)\n",
    "    frequencies = fftfreq(len(signal), 1/sample_rate)\n",
    "    positive_mask = frequencies >= 0\n",
    "    \n",
    "    freq_positive = frequencies[positive_mask]\n",
    "    amplitude_positive = np.abs(fft_result[positive_mask])\n",
    "    \n",
    "    # HPS計算\n",
    "    hps = amplitude_positive.copy()\n",
    "    \n",
    "    for harmonic in range(2, num_harmonics + 1):\n",
    "        # スペクトルをダウンサンプリング\n",
    "        downsampled_length = len(amplitude_positive) // harmonic\n",
    "        downsampled = amplitude_positive[:downsampled_length * harmonic:harmonic]\n",
    "        \n",
    "        # 積を計算\n",
    "        hps[:len(downsampled)] *= downsampled\n",
    "    \n",
    "    # ピッチ検出\n",
    "    # 低周波数ノイズを除去\n",
    "    min_freq_idx = np.where(freq_positive >= 50)[0]\n",
    "    if len(min_freq_idx) > 0:\n",
    "        search_start = min_freq_idx[0]\n",
    "        max_freq_idx = np.where(freq_positive <= 800)[0]\n",
    "        search_end = max_freq_idx[-1] if len(max_freq_idx) > 0 else len(hps)\n",
    "        \n",
    "        search_hps = hps[search_start:search_end]\n",
    "        peak_idx = np.argmax(search_hps) + search_start\n",
    "        detected_pitch = freq_positive[peak_idx]\n",
    "    else:\n",
    "        detected_pitch = 0\n",
    "    \n",
    "    return detected_pitch, hps, freq_positive, amplitude_positive\n",
    "\n",
    "# 複雑な音響信号でのテスト\n",
    "complex_signals = {\n",
    "    '基音+倍音': lambda f, t: (np.sin(2*np.pi*f*t) + 0.5*np.sin(2*np.pi*f*2*t) + 0.3*np.sin(2*np.pi*f*3*t)),\n",
    "    '欠損基音': lambda f, t: (0.6*np.sin(2*np.pi*f*2*t) + 0.4*np.sin(2*np.pi*f*3*t) + 0.3*np.sin(2*np.pi*f*4*t)),\n",
    "    '不協和音': lambda f, t: (np.sin(2*np.pi*f*t) + np.sin(2*np.pi*(f*1.1)*t)),\n",
    "    'コード': lambda f, t: (np.sin(2*np.pi*f*t) + np.sin(2*np.pi*(f*5/4)*t) + np.sin(2*np.pi*(f*3/2)*t))\n",
    "}\n",
    "\n",
    "test_frequency = 200  # Hz\n",
    "\n",
    "plt.figure(figsize=(16, 16))\n",
    "\n",
    "for i, (signal_name, signal_func) in enumerate(complex_signals.items()):\n",
    "    # 信号生成\n",
    "    signal = signal_func(test_frequency, t)\n",
    "    \n",
    "    # 各手法でピッチ検出\n",
    "    autocorr_pitch, autocorr_conf, _, _ = autocorrelation_pitch_detection(signal, sample_rate)\n",
    "    fft_pitch, fft_score, freq_pos, amp_pos, peak_freqs, peak_amps = fft_pitch_detection(signal, sample_rate)\n",
    "    hps_pitch, hps, freq_hps, amp_hps = harmonic_product_spectrum(signal, sample_rate)\n",
    "    \n",
    "    # 時間波形\n",
    "    plt.subplot(4, 4, i*4 + 1)\n",
    "    plt.plot(t[:400], signal[:400], 'b-', linewidth=2)\n",
    "    plt.title(f'{signal_name}（時間波形）')\n",
    "    plt.ylabel('振幅')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # FFTスペクトル\n",
    "    plt.subplot(4, 4, i*4 + 2)\n",
    "    plt.plot(freq_pos, amp_pos, 'b-', alpha=0.7, linewidth=1)\n",
    "    plt.plot(peak_freqs, peak_amps, 'ro', markersize=6, alpha=0.8)\n",
    "    plt.axvline(x=fft_pitch, color='red', linestyle='--', label=f'FFT: {fft_pitch:.1f} Hz')\n",
    "    plt.title('FFTスペクトルとピーク')\n",
    "    plt.ylabel('振幅')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, 1000)\n",
    "    \n",
    "    # HPSスペクトル\n",
    "    plt.subplot(4, 4, i*4 + 3)\n",
    "    plt.plot(freq_hps, amp_hps, 'b-', alpha=0.7, label='元スペクトル')\n",
    "    plt.plot(freq_hps, hps / np.max(hps) * np.max(amp_hps), 'g-', linewidth=2, label='HPS')\n",
    "    plt.axvline(x=hps_pitch, color='green', linestyle='--', label=f'HPS: {hps_pitch:.1f} Hz')\n",
    "    plt.title('Harmonic Product Spectrum')\n",
    "    plt.ylabel('振幅')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, 1000)\n",
    "    \n",
    "    # 結果比較\n",
    "    plt.subplot(4, 4, i*4 + 4)\n",
    "    methods = ['真値', '自己相関', 'FFT', 'HPS']\n",
    "    pitches = [test_frequency, autocorr_pitch, fft_pitch, hps_pitch]\n",
    "    colors = ['black', 'blue', 'red', 'green']\n",
    "    \n",
    "    bars = plt.bar(methods, pitches, color=colors, alpha=0.7)\n",
    "    plt.axhline(y=test_frequency, color='black', linestyle='--', alpha=0.5)\n",
    "    plt.title('ピッチ検出結果比較')\n",
    "    plt.ylabel('周波数 (Hz)')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # 数値を表示\n",
    "    for bar, pitch in zip(bars, pitches):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,\n",
    "                f'{pitch:.1f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"各手法の特徴:\")\n",
    "print(\"1. 自己相関法: 周期性を利用、倍音に強い\")\n",
    "print(\"2. FFT法: 倍音パターン認識、複雑な音に対応\")\n",
    "print(\"3. HPS法: 基音が欠損していても検出可能\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習問題\n",
    "\n",
    "1. 楽器の音を録音して、異なるピッチ検出法の精度を比較してみましょう\n",
    "2. ノイズの多い環境での各手法の頑健性を評価してみましょう\n",
    "3. リアルタイムピッチ検出システムを実装してみましょう"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}