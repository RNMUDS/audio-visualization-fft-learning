{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 機械学習による音響分類と特徴抽出\n",
    "\n",
    "このノートブックでは、機械学習を使用した音響信号の分類と特徴抽出について学習します。\n",
    "音響の特徴量抽出から簡単な分類器の構築まで実践的に学びます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "from scipy import signal\n",
    "from pydub import AudioSegment\n",
    "from pydub.generators import Sine, Square, Sawtooth\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 日本語フォントの設定\n",
    "plt.rcParams['font.family'] = 'DejaVu Sans'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 音響データセットの生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_audio_dataset(n_samples_per_class=50):\n",
    "    \"\"\"\n",
    "    異なる種類の音響信号を生成\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    labels = []\n",
    "    \n",
    "    sample_rate = 1000\n",
    "    duration = 1.0  # 1秒\n",
    "    t = np.linspace(0, duration, int(sample_rate * duration), False)\n",
    "    \n",
    "    for i in range(n_samples_per_class):\n",
    "        # 1. 純粋な正弦波（楽器音）\n",
    "        freq = np.random.uniform(200, 800)\n",
    "        signal_sine = np.sin(2 * np.pi * freq * t)\n",
    "        # エンベロープ追加\n",
    "        envelope = np.exp(-t * 2)  # 減衰\n",
    "        signal_sine *= envelope\n",
    "        # ランダムノイズ追加\n",
    "        signal_sine += 0.05 * np.random.randn(len(signal_sine))\n",
    "        samples.append(signal_sine)\n",
    "        labels.append(0)  # 楽器音\n",
    "        \n",
    "        # 2. ノイズ（雑音）\n",
    "        signal_noise = np.random.randn(len(t))\n",
    "        # ローパスフィルタでホワイトノイズを調整\n",
    "        b, a = signal.butter(4, 0.3)\n",
    "        signal_noise = signal.filtfilt(b, a, signal_noise)\n",
    "        samples.append(signal_noise)\n",
    "        labels.append(1)  # ノイズ\n",
    "        \n",
    "        # 3. チャープ信号（周波数変化）\n",
    "        f0, f1 = 100, 500\n",
    "        signal_chirp = signal.chirp(t, f0, duration, f1)\n",
    "        signal_chirp += 0.1 * np.random.randn(len(signal_chirp))\n",
    "        samples.append(signal_chirp)\n",
    "        labels.append(2)  # チャープ\n",
    "        \n",
    "        # 4. 複合音（和音）\n",
    "        freqs = [200, 300, 400, 500]\n",
    "        signal_chord = np.zeros_like(t)\n",
    "        for f in freqs:\n",
    "            signal_chord += np.sin(2 * np.pi * f * t) * np.exp(-t * 1.5)\n",
    "        signal_chord += 0.05 * np.random.randn(len(signal_chord))\n",
    "        samples.append(signal_chord)\n",
    "        labels.append(3)  # 和音\n",
    "    \n",
    "    return np.array(samples), np.array(labels)\n",
    "\n",
    "# データセット生成\n",
    "X, y = generate_audio_dataset(100)\n",
    "class_names = ['Instrument', 'Noise', 'Chirp', 'Chord']\n",
    "\n",
    "print(f\"データセットサイズ: {X.shape}\")\n",
    "print(f\"クラス分布: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. サンプル音響データの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各クラスのサンプルを表示\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "for class_idx in range(4):\n",
    "    # 最初のサンプルを取得\n",
    "    sample_idx = np.where(y == class_idx)[0][0]\n",
    "    sample_data = X[sample_idx]\n",
    "    \n",
    "    # 時間領域\n",
    "    axes[0, class_idx].plot(sample_data)\n",
    "    axes[0, class_idx].set_title(f'{class_names[class_idx]} - Time Domain')\n",
    "    axes[0, class_idx].set_ylabel('Amplitude')\n",
    "    axes[0, class_idx].grid(True)\n",
    "    \n",
    "    # 周波数領域\n",
    "    freqs, psd = signal.periodogram(sample_data, fs=1000)\n",
    "    axes[1, class_idx].semilogy(freqs, psd)\n",
    "    axes[1, class_idx].set_title(f'{class_names[class_idx]} - Frequency Domain')\n",
    "    axes[1, class_idx].set_xlabel('Frequency (Hz)')\n",
    "    axes[1, class_idx].set_ylabel('PSD')\n",
    "    axes[1, class_idx].grid(True)\n",
    "    axes[1, class_idx].set_xlim(0, 500)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 音響特徴量の抽出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(audio_samples, fs=1000):\n",
    "    \"\"\"\n",
    "    音響信号から特徴量を抽出\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    \n",
    "    for sample in audio_samples:\n",
    "        feature_vector = []\n",
    "        \n",
    "        # 1. 時間領域の特徴\n",
    "        feature_vector.append(np.mean(sample))  # 平均\n",
    "        feature_vector.append(np.std(sample))   # 標準偏差\n",
    "        feature_vector.append(np.max(sample))   # 最大値\n",
    "        feature_vector.append(np.min(sample))   # 最小値\n",
    "        feature_vector.append(np.sqrt(np.mean(sample**2)))  # RMS\n",
    "        \n",
    "        # ゼロクロス率\n",
    "        zero_crossings = np.where(np.diff(np.signbit(sample)))[0]\n",
    "        feature_vector.append(len(zero_crossings) / len(sample))\n",
    "        \n",
    "        # 2. 周波数領域の特徴\n",
    "        freqs, psd = signal.periodogram(sample, fs=fs)\n",
    "        \n",
    "        # スペクトル重心\n",
    "        spectral_centroid = np.sum(freqs * psd) / np.sum(psd)\n",
    "        feature_vector.append(spectral_centroid)\n",
    "        \n",
    "        # スペクトル帯域幅\n",
    "        spectral_bandwidth = np.sqrt(np.sum(((freqs - spectral_centroid) ** 2) * psd) / np.sum(psd))\n",
    "        feature_vector.append(spectral_bandwidth)\n",
    "        \n",
    "        # スペクトルロールオフ\n",
    "        cumsum_psd = np.cumsum(psd)\n",
    "        rolloff_idx = np.where(cumsum_psd >= 0.85 * cumsum_psd[-1])[0][0]\n",
    "        spectral_rolloff = freqs[rolloff_idx]\n",
    "        feature_vector.append(spectral_rolloff)\n",
    "        \n",
    "        # 主要周波数成分（ピーク検出）\n",
    "        peaks, _ = signal.find_peaks(psd, height=np.max(psd) * 0.1)\n",
    "        if len(peaks) > 0:\n",
    "            dominant_freq = freqs[peaks[np.argmax(psd[peaks])]]\n",
    "            feature_vector.append(dominant_freq)\n",
    "            feature_vector.append(len(peaks))  # ピーク数\n",
    "        else:\n",
    "            feature_vector.extend([0, 0])\n",
    "        \n",
    "        # 3. 統計的特徴\n",
    "        # 歪度と尖度\n",
    "        from scipy.stats import skew, kurtosis\n",
    "        feature_vector.append(skew(sample))\n",
    "        feature_vector.append(kurtosis(sample))\n",
    "        \n",
    "        # エネルギー\n",
    "        feature_vector.append(np.sum(sample**2))\n",
    "        \n",
    "        features.append(feature_vector)\n",
    "    \n",
    "    return np.array(features)\n",
    "\n",
    "# 特徴量抽出\n",
    "features = extract_features(X)\n",
    "feature_names = ['Mean', 'Std', 'Max', 'Min', 'RMS', 'ZCR', \n",
    "                'SpectralCentroid', 'SpectralBandwidth', 'SpectralRolloff',\n",
    "                'DominantFreq', 'NumPeaks', 'Skewness', 'Kurtosis', 'Energy']\n",
    "\n",
    "print(f\"特徴量の形状: {features.shape}\")\n",
    "print(f\"特徴量名: {feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 特徴量の可視化と分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の分布を可視化\n",
    "fig, axes = plt.subplots(3, 5, figsize=(20, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature_name in enumerate(feature_names):\n",
    "    if i < len(axes):\n",
    "        for class_idx, class_name in enumerate(class_names):\n",
    "            class_features = features[y == class_idx, i]\n",
    "            axes[i].hist(class_features, alpha=0.7, label=class_name, bins=20)\n",
    "        \n",
    "        axes[i].set_title(feature_name)\n",
    "        axes[i].legend()\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# 最後のサブプロットを削除\n",
    "if len(feature_names) < len(axes):\n",
    "    fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量間の相関分析\n",
    "import pandas as pd\n",
    "\n",
    "# データフレーム作成\n",
    "df_features = pd.DataFrame(features, columns=feature_names)\n",
    "df_features['class'] = y\n",
    "\n",
    "# 相関行列\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df_features.drop('class', axis=1).corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PCAによる次元削減と可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徴量の標準化\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# PCA適用\n",
    "pca = PCA()\n",
    "features_pca = pca.fit_transform(features_scaled)\n",
    "\n",
    "# 累積寄与率の可視化\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "         pca.explained_variance_ratio_, 'bo-')\n",
    "plt.title('PCA Explained Variance Ratio')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(1, len(pca.explained_variance_ratio_) + 1), \n",
    "         np.cumsum(pca.explained_variance_ratio_), 'ro-')\n",
    "plt.axhline(y=0.95, color='k', linestyle='--', alpha=0.7)\n",
    "plt.title('Cumulative Explained Variance')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "\n",
    "# 2次元PCAプロット\n",
    "plt.subplot(1, 3, 3)\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "for class_idx, (class_name, color) in enumerate(zip(class_names, colors)):\n",
    "    class_indices = y == class_idx\n",
    "    plt.scatter(features_pca[class_indices, 0], features_pca[class_indices, 1], \n",
    "               c=color, label=class_name, alpha=0.7)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.title('PCA Visualization (2D)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"95%の分散を説明するのに必要な成分数: {np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 機械学習による分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_scaled, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Random Forest分類器の訓練\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# 予測\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# 性能評価\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "\n",
    "# 混同行列\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n",
    "# 特徴量重要度\n",
    "feature_importance = rf_classifier.feature_importances_\n",
    "sorted_indices = np.argsort(feature_importance)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(feature_importance)), feature_importance[sorted_indices])\n",
    "plt.xticks(range(len(feature_importance)), \n",
    "           [feature_names[i] for i in sorted_indices], rotation=45)\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.ylabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 新しい音響データの分類予測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新しいテストサンプルの生成\n",
    "def generate_test_sample(signal_type='mystery'):\n",
    "    \"\"\"\n",
    "    新しいテストサンプルを生成\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, 1, 1000, False)\n",
    "    \n",
    "    if signal_type == 'mystery':\n",
    "        # 複雑な信号（複数の要素を組み合わせ）\n",
    "        signal_data = (np.sin(2 * np.pi * 250 * t) * np.exp(-t * 2) +  # 楽器的成分\n",
    "                      0.3 * np.random.randn(len(t)) +  # ノイズ成分\n",
    "                      0.5 * np.sin(2 * np.pi * 300 * t) * np.exp(-t * 1.5))  # 和音成分\n",
    "    else:\n",
    "        # シンプルなテスト信号\n",
    "        signal_data = np.sin(2 * np.pi * 400 * t) + 0.1 * np.random.randn(len(t))\n",
    "    \n",
    "    return signal_data\n",
    "\n",
    "# テストサンプルの生成と分類\n",
    "test_samples = []\n",
    "test_types = ['mystery', 'simple']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, signal_type in enumerate(test_types):\n",
    "    test_sample = generate_test_sample(signal_type)\n",
    "    test_samples.append(test_sample)\n",
    "    \n",
    "    # 特徴量抽出\n",
    "    test_features = extract_features([test_sample])\n",
    "    test_features_scaled = scaler.transform(test_features)\n",
    "    \n",
    "    # 予測\n",
    "    prediction = rf_classifier.predict(test_features_scaled)[0]\n",
    "    probabilities = rf_classifier.predict_proba(test_features_scaled)[0]\n",
    "    \n",
    "    # 可視化\n",
    "    axes[i*2].plot(test_sample)\n",
    "    axes[i*2].set_title(f'Test Sample {i+1} ({signal_type})\\nPredicted: {class_names[prediction]}')\n",
    "    axes[i*2].set_ylabel('Amplitude')\n",
    "    axes[i*2].grid(True)\n",
    "    \n",
    "    # 周波数スペクトル\n",
    "    freqs, psd = signal.periodogram(test_sample, fs=1000)\n",
    "    axes[i*2+1].semilogy(freqs, psd)\n",
    "    axes[i*2+1].set_title('Frequency Spectrum')\n",
    "    axes[i*2+1].set_xlabel('Frequency (Hz)')\n",
    "    axes[i*2+1].set_ylabel('PSD')\n",
    "    axes[i*2+1].grid(True)\n",
    "    axes[i*2+1].set_xlim(0, 500)\n",
    "    \n",
    "    print(f\"\\nTest Sample {i+1} ({signal_type}):\")\n",
    "    print(f\"Predicted Class: {class_names[prediction]}\")\n",
    "    print(\"Class Probabilities:\")\n",
    "    for j, (class_name, prob) in enumerate(zip(class_names, probabilities)):\n",
    "        print(f\"  {class_name}: {prob:.3f}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 学習曲線とモデル性能の分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve, validation_curve\n",
    "\n",
    "# 学習曲線\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    rf_classifier, features_scaled, y, cv=5, \n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), random_state=42\n",
    ")\n",
    "\n",
    "# 結果の可視化\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# 学習曲線\n",
    "plt.subplot(1, 3, 1)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training Score')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "plt.plot(train_sizes, val_mean, 'o-', color='red', label='Validation Score')\n",
    "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')\n",
    "\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Learning Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 検証曲線（木の数による性能変化）\n",
    "plt.subplot(1, 3, 2)\n",
    "param_range = [10, 20, 50, 100, 200, 500]\n",
    "train_scores_val, val_scores_val = validation_curve(\n",
    "    RandomForestClassifier(random_state=42), features_scaled, y,\n",
    "    param_name='n_estimators', param_range=param_range, cv=5\n",
    ")\n",
    "\n",
    "train_mean_val = np.mean(train_scores_val, axis=1)\n",
    "val_mean_val = np.mean(val_scores_val, axis=1)\n",
    "\n",
    "plt.plot(param_range, train_mean_val, 'o-', color='blue', label='Training Score')\n",
    "plt.plot(param_range, val_mean_val, 'o-', color='red', label='Validation Score')\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Validation Curve (n_estimators)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xscale('log')\n",
    "\n",
    "# 各クラスの予測確率分布\n",
    "plt.subplot(1, 3, 3)\n",
    "test_probs = rf_classifier.predict_proba(X_test)\n",
    "max_probs = np.max(test_probs, axis=1)\n",
    "predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "for class_idx, class_name in enumerate(class_names):\n",
    "    class_mask = y_test == class_idx\n",
    "    class_probs = max_probs[class_mask]\n",
    "    plt.hist(class_probs, alpha=0.7, label=class_name, bins=20)\n",
    "\n",
    "plt.xlabel('Maximum Prediction Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Prediction Confidence Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Model Performance:\")\n",
    "print(f\"Training Accuracy: {rf_classifier.score(X_train, y_train):.3f}\")\n",
    "print(f\"Test Accuracy: {rf_classifier.score(X_test, y_test):.3f}\")\n",
    "print(f\"Average Prediction Confidence: {np.mean(max_probs):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}